import os
import glob
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer, ENGLISH_STOP_WORDS
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from wordcloud import WordCloud

# --- 1. åˆä½µæ‰€æœ‰æ¨æ–‡è³‡æ–™ ---
csv_files = sorted(glob.glob("data/tariff_data_en/*.csv"))
df_list = [pd.read_csv(f) for f in csv_files]
df = pd.concat(df_list, ignore_index=True)

# --- 2. æ¨™æº–åŒ–æ¬„ä½èˆ‡æ™‚é–“è™•ç† ---
df.columns = ['Timestamp', 'text', 'sentiment']
df.dropna(subset=['text'], inplace=True)
df['Timestamp'] = pd.to_datetime(df['Timestamp'])  # å« UTC æ™‚å€

# ä¿®æ­£ï¼šé¿å… tz-aware / naive éŒ¯èª¤ï¼Œæ˜ç¢ºæŒ‡å®šäº‹ä»¶æ—¥ç‚º UTC æ™‚é–“
event_date = pd.to_datetime("2025-04-02").tz_localize("UTC")
df['period'] = df['Timestamp'].apply(lambda x: 'before' if x < event_date else 'after')

# --- 3. å‘é‡åŒ–æ¨æ–‡ï¼ˆTF-IDFï¼‰---
custom_stopwords = set(['tariff', 'trump'])  # ä½ å¯ä»¥åŠ å…¥æ›´å¤šå¸¸è¦‹è©
all_stopwords = list(ENGLISH_STOP_WORDS.union(custom_stopwords))  # ä¿®æ­£éŒ¯èª¤ï¼šè½‰æˆ list æ‰èƒ½å‚³å…¥
vectorizer = TfidfVectorizer(stop_words=all_stopwords, max_features=1000)
X = vectorizer.fit_transform(df['text'])

# --- 4. KMeans èšé¡ ---
k = 6
kmeans = KMeans(n_clusters=k, random_state=42)
df['cluster'] = kmeans.fit_predict(X)

# --- 5. PCA é™ç¶­ + ç•«ç¾¤é«”åˆ†å¸ƒåœ– ---
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X.toarray())

os.makedirs("saved_imgs", exist_ok=True)

plt.figure(figsize=(10, 7))
scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='tab10', alpha=0.6)
plt.title("KMeans(PCA)")
plt.xlabel("PCA 1")
plt.ylabel("PCA 2")
plt.colorbar(scatter, label='Cluster')
plt.savefig("saved_imgs/kmeans_pca_clusters.png")
plt.close()

# --- 6. ç”¢å‡ºæ¯å€‹ç¾¤çš„ WordCloud ---
def plot_cluster_wordcloud(df, cluster_num):
    text = " ".join(df[df['cluster'] == cluster_num]['text'])
    wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=all_stopwords).generate(text)
    plt.figure(figsize=(10, 5))
    plt.imshow(wordcloud, interpolation='bilinear')
    plt.axis("off")
    plt.title(f"Cluster {cluster_num} WordCloud")
    plt.savefig(f"saved_imgs/cluster_{cluster_num}_wordcloud.png")
    plt.close()

for cl in sorted(df['cluster'].unique()):
    plot_cluster_wordcloud(df, cl)

# --- 7. é¡å¤–åˆ†æè¼¸å‡ºï¼šäº‹ä»¶å‰å¾Œå„ç¾¤æ•¸é‡èˆ‡æƒ…ç·’åˆ†å¸ƒ ---
print("\nğŸ“Š å„ç¾¤æƒ…ç·’æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:")
print(df.groupby('cluster')['sentiment'].value_counts(normalize=True).unstack().fillna(0))

print("\nğŸ“† å„ç¾¤åœ¨äº‹ä»¶å‰/å¾Œçš„æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:")
print(pd.crosstab(df['cluster'], df['period'], normalize='index'))
