{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (1.15.0)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, safetensors, pyyaml, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12.1\n",
      "    Uninstalling sympy-1.12.1:\n",
      "      Successfully uninstalled sympy-1.12.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pennylane-qiskit 0.41.0.post0 requires qiskit<1.3,>=0.32, but you have qiskit 1.4.2 which is incompatible.\n",
      "pennylane-qiskit 0.41.0.post0 requires sympy<1.13, but you have sympy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.31.4 pyyaml-6.0.2 safetensors-0.5.3 sentence_transformers-4.1.0 sympy-1.14.0 tokenizers-0.21.1 transformers-4.52.3\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from wordcloud import WordCloud\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet Content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-01T22:17:49.000Z</td>\n",
       "      <td>Proposed tariffs on China, Canada, and Mexico ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-01T22:27:25.000Z</td>\n",
       "      <td>President Trump says his 25-percent tariff on ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-01T23:00:01.000Z</td>\n",
       "      <td>\"You should pay less for someone that has tari...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-01T23:00:01.000Z</td>\n",
       "      <td>\"You should pay less for someone that has tari...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-01T22:30:20.000Z</td>\n",
       "      <td>Beer Companies Say Trump’s Aluminum Tariff Wil...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp  \\\n",
       "0  2025-03-01T22:17:49.000Z   \n",
       "1  2025-03-01T22:27:25.000Z   \n",
       "2  2025-03-01T23:00:01.000Z   \n",
       "3  2025-03-01T23:00:01.000Z   \n",
       "4  2025-03-01T22:30:20.000Z   \n",
       "\n",
       "                                       Tweet Content sentiment  \n",
       "0  Proposed tariffs on China, Canada, and Mexico ...  positive  \n",
       "1  President Trump says his 25-percent tariff on ...  positive  \n",
       "2  \"You should pay less for someone that has tari...  negative  \n",
       "3  \"You should pay less for someone that has tari...  negative  \n",
       "4  Beer Companies Say Trump’s Aluminum Tariff Wil...  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. 合併所有推文資料 ---\n",
    "csv_files = sorted(glob.glob(\"data/tariff_data_en/*.csv\"))\n",
    "df_list = [pd.read_csv(f) for f in csv_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. 標準化欄位與時間處理 ---\n",
    "df.columns = ['Timestamp', 'text', 'sentiment']\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])  # 含 UTC 時區\n",
    "event_date = pd.to_datetime(\"2025-04-02\").tz_localize(\"UTC\")\n",
    "df['period'] = df['Timestamp'].apply(lambda x: 'before' if x < event_date else 'after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Batches: 100%|██████████| 280/280 [00:21<00:00, 13.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- 3. 使用預訓練 Sentence-BERT 將推文轉成語意向量 ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # 輕量快速\n",
    "X = model.encode(df['text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. KMeans 聚類 ---\n",
    "k = 6\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. PCA 降維 + 畫群體分布圖 ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "os.makedirs(\"saved_imgs\", exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='tab10', alpha=0.6)\n",
    "plt.title(\"KMeans with SBERT Embedding (PCA)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.savefig(\"saved_imgs/kmeans_pca_sbert.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. 產出每個群的 WordCloud（照舊）---\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "custom_stopwords = set(['tariff', 'trump'])\n",
    "all_stopwords = list(ENGLISH_STOP_WORDS.union(custom_stopwords))\n",
    "\n",
    "def plot_cluster_wordcloud(df, cluster_num):\n",
    "    text = \" \".join(df[df['cluster'] == cluster_num]['text'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=all_stopwords).generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Cluster {cluster_num} WordCloud\")\n",
    "    plt.savefig(f\"saved_imgs/cluster_{cluster_num}_wordcloud_sbert.png\")\n",
    "    plt.close()\n",
    "\n",
    "for cl in sorted(df['cluster'].unique()):\n",
    "    plot_cluster_wordcloud(df, cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🧠 群體語意總覽分析\n",
    "\n",
    "本研究以 Sentence-BERT 模型將推文轉換為語意向量，並透過 KMeans 聚類方法將語料分為六個主題群。經由每群高頻詞彙的詞雲（word cloud）視覺化與語意對照分析後，歸納出各群的核心語境與主題如下：\n",
    "\n",
    "- **Cluster 0 – 美加貿易爭端與加拿大觀點**  \n",
    "  該群體聚焦於加拿大與美國之間的貿易關係，頻繁出現的詞彙包含 `Canada`, `Trudeau`, `threat`, `tariffs`，顯示該群多為對美方政策持批評態度的推文，語氣偏向防禦與不滿。\n",
    "\n",
    "- **Cluster 1 – 市場波動與投資反應**  \n",
    "  此群包含大量與金融市場相關語彙，如 `market`, `stock`, `investor`, `recession`，反映出用戶對於貿易政策可能對經濟與股市造成影響的擔憂與分析，語氣呈現理性但偏焦慮。\n",
    "\n",
    "- **Cluster 2 – 中美貿易戰與國際談判**  \n",
    "  詞彙如 `China`, `export`, `deal`, `war` 明確指出該群主題為中美貿易衝突與談判進展，語氣多帶有對抗性或批判性，且事件後大量湧現，為本研究中最受事件影響的群體。\n",
    "\n",
    "- **Cluster 3 – 關稅影響與消費經濟**  \n",
    "  該群多出現 `cost`, `import`, `consumer`, `price`，代表對關稅政策對商品價格與消費者負擔的關注。語氣較為理性、經濟分析導向，屬於討論型內容。\n",
    "\n",
    "- **Cluster 4 – 政策評論與官方言論反應**  \n",
    "  含有 `President`, `policy`, `economy`, `administration` 等詞彙，代表該群集中在政府官員與政策制定者的發言評論，語氣可能因政治立場不同而分化，整體呈現評論性與新聞轉述性質。\n",
    "\n",
    "- **Cluster 5 – 網民輿論與口語表態**  \n",
    "  本群聚焦於網路社群中的一般輿論，詞彙如 `just`, `say`, `like`, `want` 表現出明顯的非正式、情緒化用語，語氣較為自由、多樣，並包含支持、諷刺與戲謔等多元觀點，是情緒最偏向正面的群體。\n",
    "\n",
    "整體而言，分群結果有效劃分了不同語意主題，並揭示了政策事件如何在語意與情緒層面觸發特定群體的反應，為理解社群輿\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 📋 群體語意總覽表格\n",
    "\n",
    "| Cluster | 主題焦點                         | 高頻關鍵詞（部分）                           | 語氣傾向         | 備註                             |\n",
    "|---------|----------------------------------|----------------------------------------------|------------------|----------------------------------|\n",
    "| 0       | 美加貿易爭端與加拿大觀點         | Canada, Trudeau, threat, tariffs, US         | 負面、批判       | 舊議題為主，事件前集中出現       |\n",
    "| 1       | 市場波動與投資反應               | market, stock, investor, recession, risk     | 焦慮、理性       | 與金融市場連動，反應全球不安     |\n",
    "| 2       | 中美貿易戰與國際談判             | China, deal, war, export, negotiation        | 對立、憤怒       | 事件後激增，情緒最負面           |\n",
    "| 3       | 關稅影響與消費經濟               | cost, import, consumer, price, impact        | 中性、理性       | 關注稅收與價格影響               |\n",
    "| 4       | 政策評論與官方言論反應           | President, policy, administration, economy   | 評論、兩極       | 涉及領導人與政府發言             |\n",
    "| 5       | 網民輿論與口語表態               | just, like, say, want, week, new             | 多元、偏正向     | 社群用語多，情緒最活躍           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 各群情緒比例（row-normalized）:\n",
      "sentiment  negative   neutral  positive\n",
      "cluster                                \n",
      "0          0.501894  0.174242  0.323864\n",
      "1          0.536533  0.127507  0.335960\n",
      "2          0.549412  0.164706  0.285882\n",
      "3          0.380933  0.251810  0.367257\n",
      "4          0.504292  0.194421  0.301288\n",
      "5          0.425767  0.164417  0.409816\n",
      "\n",
      "📆 各群在事件前/後的比例（row-normalized）:\n",
      "period      after    before\n",
      "cluster                    \n",
      "0        0.089015  0.910985\n",
      "1        0.393266  0.606734\n",
      "2        0.755294  0.244706\n",
      "3        0.446903  0.553097\n",
      "4        0.443348  0.556652\n",
      "5        0.461350  0.538650\n"
     ]
    }
   ],
   "source": [
    "# --- 7. 額外分析輸出：事件前後各群數量與情緒分布 ---\n",
    "print(\"\\n📊 各群情緒比例（row-normalized）:\")\n",
    "print(df.groupby('cluster')['sentiment'].value_counts(normalize=True).unstack().fillna(0))\n",
    "\n",
    "print(\"\\n📆 各群在事件前/後的比例（row-normalized）:\")\n",
    "print(pd.crosstab(df['cluster'], df['period'], normalize='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分群情緒傾向與事件前後分布分析 （GPT）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為探討推文內容在語意與情緒上的異質性，我們使用 Sentence-BERT 嵌入向量與 KMeans 聚類對語料進行分群（共六群），並進一步分析各群的情緒比例及其在關稅政策事件（2025 年 4 月 2 日）前後的出現頻率。下列為各群重點分析結果：\n",
    "\n",
    "1. 情緒傾向分析\n",
    "透過原始資料中的情緒標註（positive、neutral、negative），我們計算了各群體內部的情緒分布。結果顯示，群 0、1、2 的負面情緒比例皆超過 50%，反映其內容多涉及爭議性話題或批判性語言。特別是群 2，負面情緒高達 54.9%，其主題以中美貿易戰為主，詞彙如 \"Chinese\", \"war\", \"export\", \"negotiation\" 明顯帶有強烈對立語意。\n",
    "\n",
    "相較之下，群 3 與群 5 呈現相對中性或偏向正向情緒，其中群 5 的正向情緒比例最高（約 40.9%），顯示該群文本多以網民口語評論為主，語氣較為自由且表達支持、讚許等情緒的比例較高。群 3 則多與消費者成本、進口商品相關，語氣相對理性與分散。\n",
    "\n",
    "2. 事件前後出現比例分析\n",
    "對於事件時間（2025-04-02）前後的分布，我們發現各群反應明顯不同。群 2 的推文有超過 75% 發生於事件之後，顯示該主題與該事件（如新一輪關稅政策、重大外交爭端）有高度相關性，並引發大量後續討論。相對而言，群 0 的推文 91% 發生在事件之前，推測與早期美加貿易爭端相關的議題熱度已逐漸退燒。\n",
    "\n",
    "其他群（群 1、3、4、5）則呈現出較為平均的分布，顯示這些主題在事件前後均有持續性討論。例如群 1（市場波動與投資）、群 4（政府政策與總統發言）皆為長期關注議題，並非僅由特定事件引發。\n",
    "\n",
    "3. 總結\n",
    "綜合語意與時間分析可知，本次事件最直接影響的群體為 Cluster 2，其不僅情緒傾向偏負面，亦在事件後大量增加。此結果突顯語意分群能有效區分出對政策事件敏感的主題群，為輿情變化監控與情緒預測提供依據。未來可考慮進一步追蹤此類事件引發的次波輿論走向，並結合情緒強度與主題動態模型以強化分析深度。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
