{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence_transformers)\n",
      "  Downloading transformers-4.52.3-py3-none-any.whl.metadata (40 kB)\n",
      "Requirement already satisfied: tqdm in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (1.15.0)\n",
      "Collecting huggingface-hub>=0.20.0 (from sentence_transformers)\n",
      "  Downloading huggingface_hub-0.31.4-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: Pillow in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (11.1.0)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sentence_transformers) (4.12.2)\n",
      "Requirement already satisfied: filelock in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (24.2)\n",
      "Collecting pyyaml>=5.1 (from huggingface-hub>=0.20.0->sentence_transformers)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: requests in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence_transformers) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (75.1.0)\n",
      "Collecting sympy>=1.13.3 (from torch>=1.11.0->sentence_transformers)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from torch>=1.11.0->sentence_transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2.2.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence_transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from scikit-learn->sentence_transformers) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence_transformers) (2024.12.14)\n",
      "Downloading sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Downloading huggingface_hub-0.31.4-py3-none-any.whl (489 kB)\n",
      "Downloading transformers-4.52.3-py3-none-any.whl (10.5 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.5/10.5 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl (171 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sympy, safetensors, pyyaml, huggingface-hub, tokenizers, transformers, sentence_transformers\n",
      "  Attempting uninstall: sympy\n",
      "    Found existing installation: sympy 1.12.1\n",
      "    Uninstalling sympy-1.12.1:\n",
      "      Successfully uninstalled sympy-1.12.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pennylane-qiskit 0.41.0.post0 requires qiskit<1.3,>=0.32, but you have qiskit 1.4.2 which is incompatible.\n",
      "pennylane-qiskit 0.41.0.post0 requires sympy<1.13, but you have sympy 1.14.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed huggingface-hub-0.31.4 pyyaml-6.0.2 safetensors-0.5.3 sentence_transformers-4.1.0 sympy-1.14.0 tokenizers-0.21.1 transformers-4.52.3\n"
     ]
    }
   ],
   "source": [
    "!pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric1026/qiskit/miniconda3/envs/qiskit/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from wordcloud import WordCloud\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet Content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-01T22:17:49.000Z</td>\n",
       "      <td>Proposed tariffs on China, Canada, and Mexico ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-01T22:27:25.000Z</td>\n",
       "      <td>President Trump says his 25-percent tariff on ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-01T23:00:01.000Z</td>\n",
       "      <td>\"You should pay less for someone that has tari...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-01T23:00:01.000Z</td>\n",
       "      <td>\"You should pay less for someone that has tari...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-01T22:30:20.000Z</td>\n",
       "      <td>Beer Companies Say Trumpâ€™s Aluminum Tariff Wil...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp  \\\n",
       "0  2025-03-01T22:17:49.000Z   \n",
       "1  2025-03-01T22:27:25.000Z   \n",
       "2  2025-03-01T23:00:01.000Z   \n",
       "3  2025-03-01T23:00:01.000Z   \n",
       "4  2025-03-01T22:30:20.000Z   \n",
       "\n",
       "                                       Tweet Content sentiment  \n",
       "0  Proposed tariffs on China, Canada, and Mexico ...  positive  \n",
       "1  President Trump says his 25-percent tariff on ...  positive  \n",
       "2  \"You should pay less for someone that has tari...  negative  \n",
       "3  \"You should pay less for someone that has tari...  negative  \n",
       "4  Beer Companies Say Trumpâ€™s Aluminum Tariff Wil...  negative  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. åˆä½µæ‰€æœ‰æ¨æ–‡è³‡æ–™ ---\n",
    "csv_files = sorted(glob.glob(\"data/tariff_data_en/*.csv\"))\n",
    "df_list = [pd.read_csv(f) for f in csv_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. æ¨™æº–åŒ–æ¬„ä½èˆ‡æ™‚é–“è™•ç† ---\n",
    "df.columns = ['Timestamp', 'text', 'sentiment']\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])  # å« UTC æ™‚å€\n",
    "event_date = pd.to_datetime(\"2025-04-02\").tz_localize(\"UTC\")\n",
    "df['period'] = df['Timestamp'].apply(lambda x: 'before' if x < event_date else 'after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:21<00:00, 13.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- 3. ä½¿ç”¨é è¨“ç·´ Sentence-BERT å°‡æ¨æ–‡è½‰æˆèªæ„å‘é‡ ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # è¼•é‡å¿«é€Ÿ\n",
    "X = model.encode(df['text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. KMeans èšé¡ ---\n",
    "k = 6\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. PCA é™ç¶­ + ç•«ç¾¤é«”åˆ†å¸ƒåœ– ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "os.makedirs(\"saved_imgs\", exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='tab10', alpha=0.6)\n",
    "plt.title(\"KMeans with SBERT Embedding (PCA)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.savefig(\"saved_imgs/kmeans_pca_sbert.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. ç”¢å‡ºæ¯å€‹ç¾¤çš„ WordCloudï¼ˆç…§èˆŠï¼‰---\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "custom_stopwords = set(['tariff', 'trump'])\n",
    "all_stopwords = list(ENGLISH_STOP_WORDS.union(custom_stopwords))\n",
    "\n",
    "def plot_cluster_wordcloud(df, cluster_num):\n",
    "    text = \" \".join(df[df['cluster'] == cluster_num]['text'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=all_stopwords).generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Cluster {cluster_num} WordCloud\")\n",
    "    plt.savefig(f\"saved_imgs/cluster_{cluster_num}_wordcloud_sbert.png\")\n",
    "    plt.close()\n",
    "\n",
    "for cl in sorted(df['cluster'].unique()):\n",
    "    plot_cluster_wordcloud(df, cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ§  ç¾¤é«”èªæ„ç¸½è¦½åˆ†æ\n",
    "\n",
    "æœ¬ç ”ç©¶ä»¥ Sentence-BERT æ¨¡å‹å°‡æ¨æ–‡è½‰æ›ç‚ºèªæ„å‘é‡ï¼Œä¸¦é€é KMeans èšé¡æ–¹æ³•å°‡èªæ–™åˆ†ç‚ºå…­å€‹ä¸»é¡Œç¾¤ã€‚ç¶“ç”±æ¯ç¾¤é«˜é »è©å½™çš„è©é›²ï¼ˆword cloudï¼‰è¦–è¦ºåŒ–èˆ‡èªæ„å°ç…§åˆ†æå¾Œï¼Œæ­¸ç´å‡ºå„ç¾¤çš„æ ¸å¿ƒèªå¢ƒèˆ‡ä¸»é¡Œå¦‚ä¸‹ï¼š\n",
    "\n",
    "- **Cluster 0 â€“ ç¾åŠ è²¿æ˜“çˆ­ç«¯èˆ‡åŠ æ‹¿å¤§è§€é»**  \n",
    "  è©²ç¾¤é«”èšç„¦æ–¼åŠ æ‹¿å¤§èˆ‡ç¾åœ‹ä¹‹é–“çš„è²¿æ˜“é—œä¿‚ï¼Œé »ç¹å‡ºç¾çš„è©å½™åŒ…å« `Canada`, `Trudeau`, `threat`, `tariffs`ï¼Œé¡¯ç¤ºè©²ç¾¤å¤šç‚ºå°ç¾æ–¹æ”¿ç­–æŒæ‰¹è©•æ…‹åº¦çš„æ¨æ–‡ï¼Œèªæ°£åå‘é˜²ç¦¦èˆ‡ä¸æ»¿ã€‚\n",
    "\n",
    "- **Cluster 1 â€“ å¸‚å ´æ³¢å‹•èˆ‡æŠ•è³‡åæ‡‰**  \n",
    "  æ­¤ç¾¤åŒ…å«å¤§é‡èˆ‡é‡‘èå¸‚å ´ç›¸é—œèªå½™ï¼Œå¦‚ `market`, `stock`, `investor`, `recession`ï¼Œåæ˜ å‡ºç”¨æˆ¶å°æ–¼è²¿æ˜“æ”¿ç­–å¯èƒ½å°ç¶“æ¿Ÿèˆ‡è‚¡å¸‚é€ æˆå½±éŸ¿çš„æ“”æ†‚èˆ‡åˆ†æï¼Œèªæ°£å‘ˆç¾ç†æ€§ä½†åç„¦æ…®ã€‚\n",
    "\n",
    "- **Cluster 2 â€“ ä¸­ç¾è²¿æ˜“æˆ°èˆ‡åœ‹éš›è«‡åˆ¤**  \n",
    "  è©å½™å¦‚ `China`, `export`, `deal`, `war` æ˜ç¢ºæŒ‡å‡ºè©²ç¾¤ä¸»é¡Œç‚ºä¸­ç¾è²¿æ˜“è¡çªèˆ‡è«‡åˆ¤é€²å±•ï¼Œèªæ°£å¤šå¸¶æœ‰å°æŠ—æ€§æˆ–æ‰¹åˆ¤æ€§ï¼Œä¸”äº‹ä»¶å¾Œå¤§é‡æ¹§ç¾ï¼Œç‚ºæœ¬ç ”ç©¶ä¸­æœ€å—äº‹ä»¶å½±éŸ¿çš„ç¾¤é«”ã€‚\n",
    "\n",
    "- **Cluster 3 â€“ é—œç¨…å½±éŸ¿èˆ‡æ¶ˆè²»ç¶“æ¿Ÿ**  \n",
    "  è©²ç¾¤å¤šå‡ºç¾ `cost`, `import`, `consumer`, `price`ï¼Œä»£è¡¨å°é—œç¨…æ”¿ç­–å°å•†å“åƒ¹æ ¼èˆ‡æ¶ˆè²»è€…è² æ“”çš„é—œæ³¨ã€‚èªæ°£è¼ƒç‚ºç†æ€§ã€ç¶“æ¿Ÿåˆ†æå°å‘ï¼Œå±¬æ–¼è¨è«–å‹å…§å®¹ã€‚\n",
    "\n",
    "- **Cluster 4 â€“ æ”¿ç­–è©•è«–èˆ‡å®˜æ–¹è¨€è«–åæ‡‰**  \n",
    "  å«æœ‰ `President`, `policy`, `economy`, `administration` ç­‰è©å½™ï¼Œä»£è¡¨è©²ç¾¤é›†ä¸­åœ¨æ”¿åºœå®˜å“¡èˆ‡æ”¿ç­–åˆ¶å®šè€…çš„ç™¼è¨€è©•è«–ï¼Œèªæ°£å¯èƒ½å› æ”¿æ²»ç«‹å ´ä¸åŒè€Œåˆ†åŒ–ï¼Œæ•´é«”å‘ˆç¾è©•è«–æ€§èˆ‡æ–°èè½‰è¿°æ€§è³ªã€‚\n",
    "\n",
    "- **Cluster 5 â€“ ç¶²æ°‘è¼¿è«–èˆ‡å£èªè¡¨æ…‹**  \n",
    "  æœ¬ç¾¤èšç„¦æ–¼ç¶²è·¯ç¤¾ç¾¤ä¸­çš„ä¸€èˆ¬è¼¿è«–ï¼Œè©å½™å¦‚ `just`, `say`, `like`, `want` è¡¨ç¾å‡ºæ˜é¡¯çš„éæ­£å¼ã€æƒ…ç·’åŒ–ç”¨èªï¼Œèªæ°£è¼ƒç‚ºè‡ªç”±ã€å¤šæ¨£ï¼Œä¸¦åŒ…å«æ”¯æŒã€è«·åˆºèˆ‡æˆ²è¬”ç­‰å¤šå…ƒè§€é»ï¼Œæ˜¯æƒ…ç·’æœ€åå‘æ­£é¢çš„ç¾¤é«”ã€‚\n",
    "\n",
    "æ•´é«”è€Œè¨€ï¼Œåˆ†ç¾¤çµæœæœ‰æ•ˆåŠƒåˆ†äº†ä¸åŒèªæ„ä¸»é¡Œï¼Œä¸¦æ­ç¤ºäº†æ”¿ç­–äº‹ä»¶å¦‚ä½•åœ¨èªæ„èˆ‡æƒ…ç·’å±¤é¢è§¸ç™¼ç‰¹å®šç¾¤é«”çš„åæ‡‰ï¼Œç‚ºç†è§£ç¤¾ç¾¤è¼¿\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“‹ ç¾¤é«”èªæ„ç¸½è¦½è¡¨æ ¼\n",
    "\n",
    "| Cluster | ä¸»é¡Œç„¦é»                         | é«˜é »é—œéµè©ï¼ˆéƒ¨åˆ†ï¼‰                           | èªæ°£å‚¾å‘         | å‚™è¨»                             |\n",
    "|---------|----------------------------------|----------------------------------------------|------------------|----------------------------------|\n",
    "| 0       | ç¾åŠ è²¿æ˜“çˆ­ç«¯èˆ‡åŠ æ‹¿å¤§è§€é»         | Canada, Trudeau, threat, tariffs, US         | è² é¢ã€æ‰¹åˆ¤       | èˆŠè­°é¡Œç‚ºä¸»ï¼Œäº‹ä»¶å‰é›†ä¸­å‡ºç¾       |\n",
    "| 1       | å¸‚å ´æ³¢å‹•èˆ‡æŠ•è³‡åæ‡‰               | market, stock, investor, recession, risk     | ç„¦æ…®ã€ç†æ€§       | èˆ‡é‡‘èå¸‚å ´é€£å‹•ï¼Œåæ‡‰å…¨çƒä¸å®‰     |\n",
    "| 2       | ä¸­ç¾è²¿æ˜“æˆ°èˆ‡åœ‹éš›è«‡åˆ¤             | China, deal, war, export, negotiation        | å°ç«‹ã€æ†¤æ€’       | äº‹ä»¶å¾Œæ¿€å¢ï¼Œæƒ…ç·’æœ€è² é¢           |\n",
    "| 3       | é—œç¨…å½±éŸ¿èˆ‡æ¶ˆè²»ç¶“æ¿Ÿ               | cost, import, consumer, price, impact        | ä¸­æ€§ã€ç†æ€§       | é—œæ³¨ç¨…æ”¶èˆ‡åƒ¹æ ¼å½±éŸ¿               |\n",
    "| 4       | æ”¿ç­–è©•è«–èˆ‡å®˜æ–¹è¨€è«–åæ‡‰           | President, policy, administration, economy   | è©•è«–ã€å…©æ¥µ       | æ¶‰åŠé ˜å°äººèˆ‡æ”¿åºœç™¼è¨€             |\n",
    "| 5       | ç¶²æ°‘è¼¿è«–èˆ‡å£èªè¡¨æ…‹               | just, like, say, want, week, new             | å¤šå…ƒã€åæ­£å‘     | ç¤¾ç¾¤ç”¨èªå¤šï¼Œæƒ…ç·’æœ€æ´»èº           |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š å„ç¾¤æƒ…ç·’æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\n",
      "sentiment  negative   neutral  positive\n",
      "cluster                                \n",
      "0          0.501894  0.174242  0.323864\n",
      "1          0.536533  0.127507  0.335960\n",
      "2          0.549412  0.164706  0.285882\n",
      "3          0.380933  0.251810  0.367257\n",
      "4          0.504292  0.194421  0.301288\n",
      "5          0.425767  0.164417  0.409816\n",
      "\n",
      "ğŸ“† å„ç¾¤åœ¨äº‹ä»¶å‰/å¾Œçš„æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\n",
      "period      after    before\n",
      "cluster                    \n",
      "0        0.089015  0.910985\n",
      "1        0.393266  0.606734\n",
      "2        0.755294  0.244706\n",
      "3        0.446903  0.553097\n",
      "4        0.443348  0.556652\n",
      "5        0.461350  0.538650\n"
     ]
    }
   ],
   "source": [
    "# --- 7. é¡å¤–åˆ†æè¼¸å‡ºï¼šäº‹ä»¶å‰å¾Œå„ç¾¤æ•¸é‡èˆ‡æƒ…ç·’åˆ†å¸ƒ ---\n",
    "print(\"\\nğŸ“Š å„ç¾¤æƒ…ç·’æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\")\n",
    "print(df.groupby('cluster')['sentiment'].value_counts(normalize=True).unstack().fillna(0))\n",
    "\n",
    "print(\"\\nğŸ“† å„ç¾¤åœ¨äº‹ä»¶å‰/å¾Œçš„æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\")\n",
    "print(pd.crosstab(df['cluster'], df['period'], normalize='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## åˆ†ç¾¤æƒ…ç·’å‚¾å‘èˆ‡äº‹ä»¶å‰å¾Œåˆ†å¸ƒåˆ†æ ï¼ˆGPTï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ç‚ºæ¢è¨æ¨æ–‡å…§å®¹åœ¨èªæ„èˆ‡æƒ…ç·’ä¸Šçš„ç•°è³ªæ€§ï¼Œæˆ‘å€‘ä½¿ç”¨ Sentence-BERT åµŒå…¥å‘é‡èˆ‡ KMeans èšé¡å°èªæ–™é€²è¡Œåˆ†ç¾¤ï¼ˆå…±å…­ç¾¤ï¼‰ï¼Œä¸¦é€²ä¸€æ­¥åˆ†æå„ç¾¤çš„æƒ…ç·’æ¯”ä¾‹åŠå…¶åœ¨é—œç¨…æ”¿ç­–äº‹ä»¶ï¼ˆ2025 å¹´ 4 æœˆ 2 æ—¥ï¼‰å‰å¾Œçš„å‡ºç¾é »ç‡ã€‚ä¸‹åˆ—ç‚ºå„ç¾¤é‡é»åˆ†æçµæœï¼š\n",
    "\n",
    "1. æƒ…ç·’å‚¾å‘åˆ†æ\n",
    "é€éåŸå§‹è³‡æ–™ä¸­çš„æƒ…ç·’æ¨™è¨»ï¼ˆpositiveã€neutralã€negativeï¼‰ï¼Œæˆ‘å€‘è¨ˆç®—äº†å„ç¾¤é«”å…§éƒ¨çš„æƒ…ç·’åˆ†å¸ƒã€‚çµæœé¡¯ç¤ºï¼Œç¾¤ 0ã€1ã€2 çš„è² é¢æƒ…ç·’æ¯”ä¾‹çš†è¶…é 50%ï¼Œåæ˜ å…¶å…§å®¹å¤šæ¶‰åŠçˆ­è­°æ€§è©±é¡Œæˆ–æ‰¹åˆ¤æ€§èªè¨€ã€‚ç‰¹åˆ¥æ˜¯ç¾¤ 2ï¼Œè² é¢æƒ…ç·’é«˜é” 54.9%ï¼Œå…¶ä¸»é¡Œä»¥ä¸­ç¾è²¿æ˜“æˆ°ç‚ºä¸»ï¼Œè©å½™å¦‚ \"Chinese\", \"war\", \"export\", \"negotiation\" æ˜é¡¯å¸¶æœ‰å¼·çƒˆå°ç«‹èªæ„ã€‚\n",
    "\n",
    "ç›¸è¼ƒä¹‹ä¸‹ï¼Œç¾¤ 3 èˆ‡ç¾¤ 5 å‘ˆç¾ç›¸å°ä¸­æ€§æˆ–åå‘æ­£å‘æƒ…ç·’ï¼Œå…¶ä¸­ç¾¤ 5 çš„æ­£å‘æƒ…ç·’æ¯”ä¾‹æœ€é«˜ï¼ˆç´„ 40.9%ï¼‰ï¼Œé¡¯ç¤ºè©²ç¾¤æ–‡æœ¬å¤šä»¥ç¶²æ°‘å£èªè©•è«–ç‚ºä¸»ï¼Œèªæ°£è¼ƒç‚ºè‡ªç”±ä¸”è¡¨é”æ”¯æŒã€è®šè¨±ç­‰æƒ…ç·’çš„æ¯”ä¾‹è¼ƒé«˜ã€‚ç¾¤ 3 å‰‡å¤šèˆ‡æ¶ˆè²»è€…æˆæœ¬ã€é€²å£å•†å“ç›¸é—œï¼Œèªæ°£ç›¸å°ç†æ€§èˆ‡åˆ†æ•£ã€‚\n",
    "\n",
    "2. äº‹ä»¶å‰å¾Œå‡ºç¾æ¯”ä¾‹åˆ†æ\n",
    "å°æ–¼äº‹ä»¶æ™‚é–“ï¼ˆ2025-04-02ï¼‰å‰å¾Œçš„åˆ†å¸ƒï¼Œæˆ‘å€‘ç™¼ç¾å„ç¾¤åæ‡‰æ˜é¡¯ä¸åŒã€‚ç¾¤ 2 çš„æ¨æ–‡æœ‰è¶…é 75% ç™¼ç”Ÿæ–¼äº‹ä»¶ä¹‹å¾Œï¼Œé¡¯ç¤ºè©²ä¸»é¡Œèˆ‡è©²äº‹ä»¶ï¼ˆå¦‚æ–°ä¸€è¼ªé—œç¨…æ”¿ç­–ã€é‡å¤§å¤–äº¤çˆ­ç«¯ï¼‰æœ‰é«˜åº¦ç›¸é—œæ€§ï¼Œä¸¦å¼•ç™¼å¤§é‡å¾ŒçºŒè¨è«–ã€‚ç›¸å°è€Œè¨€ï¼Œç¾¤ 0 çš„æ¨æ–‡ 91% ç™¼ç”Ÿåœ¨äº‹ä»¶ä¹‹å‰ï¼Œæ¨æ¸¬èˆ‡æ—©æœŸç¾åŠ è²¿æ˜“çˆ­ç«¯ç›¸é—œçš„è­°é¡Œç†±åº¦å·²é€æ¼¸é€€ç‡’ã€‚\n",
    "\n",
    "å…¶ä»–ç¾¤ï¼ˆç¾¤ 1ã€3ã€4ã€5ï¼‰å‰‡å‘ˆç¾å‡ºè¼ƒç‚ºå¹³å‡çš„åˆ†å¸ƒï¼Œé¡¯ç¤ºé€™äº›ä¸»é¡Œåœ¨äº‹ä»¶å‰å¾Œå‡æœ‰æŒçºŒæ€§è¨è«–ã€‚ä¾‹å¦‚ç¾¤ 1ï¼ˆå¸‚å ´æ³¢å‹•èˆ‡æŠ•è³‡ï¼‰ã€ç¾¤ 4ï¼ˆæ”¿åºœæ”¿ç­–èˆ‡ç¸½çµ±ç™¼è¨€ï¼‰çš†ç‚ºé•·æœŸé—œæ³¨è­°é¡Œï¼Œä¸¦éåƒ…ç”±ç‰¹å®šäº‹ä»¶å¼•ç™¼ã€‚\n",
    "\n",
    "3. ç¸½çµ\n",
    "ç¶œåˆèªæ„èˆ‡æ™‚é–“åˆ†æå¯çŸ¥ï¼Œæœ¬æ¬¡äº‹ä»¶æœ€ç›´æ¥å½±éŸ¿çš„ç¾¤é«”ç‚º Cluster 2ï¼Œå…¶ä¸åƒ…æƒ…ç·’å‚¾å‘åè² é¢ï¼Œäº¦åœ¨äº‹ä»¶å¾Œå¤§é‡å¢åŠ ã€‚æ­¤çµæœçªé¡¯èªæ„åˆ†ç¾¤èƒ½æœ‰æ•ˆå€åˆ†å‡ºå°æ”¿ç­–äº‹ä»¶æ•æ„Ÿçš„ä¸»é¡Œç¾¤ï¼Œç‚ºè¼¿æƒ…è®ŠåŒ–ç›£æ§èˆ‡æƒ…ç·’é æ¸¬æä¾›ä¾æ“šã€‚æœªä¾†å¯è€ƒæ…®é€²ä¸€æ­¥è¿½è¹¤æ­¤é¡äº‹ä»¶å¼•ç™¼çš„æ¬¡æ³¢è¼¿è«–èµ°å‘ï¼Œä¸¦çµåˆæƒ…ç·’å¼·åº¦èˆ‡ä¸»é¡Œå‹•æ…‹æ¨¡å‹ä»¥å¼·åŒ–åˆ†ææ·±åº¦ã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0404 (ç¾è‚¡é‡æŒ«)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet Content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-01T22:17:49.000Z</td>\n",
       "      <td>Proposed tariffs on China, Canada, and Mexico ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-01T22:27:25.000Z</td>\n",
       "      <td>President Trump says his 25-percent tariff on ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-01T23:00:01.000Z</td>\n",
       "      <td>\"You should pay less for someone that has tari...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-01T23:00:01.000Z</td>\n",
       "      <td>\"You should pay less for someone that has tari...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-01T22:30:20.000Z</td>\n",
       "      <td>Beer Companies Say Trumpâ€™s Aluminum Tariff Wil...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp  \\\n",
       "0  2025-03-01T22:17:49.000Z   \n",
       "1  2025-03-01T22:27:25.000Z   \n",
       "2  2025-03-01T23:00:01.000Z   \n",
       "3  2025-03-01T23:00:01.000Z   \n",
       "4  2025-03-01T22:30:20.000Z   \n",
       "\n",
       "                                       Tweet Content sentiment  \n",
       "0  Proposed tariffs on China, Canada, and Mexico ...  positive  \n",
       "1  President Trump says his 25-percent tariff on ...  positive  \n",
       "2  \"You should pay less for someone that has tari...  negative  \n",
       "3  \"You should pay less for someone that has tari...  negative  \n",
       "4  Beer Companies Say Trumpâ€™s Aluminum Tariff Wil...  negative  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. åˆä½µæ‰€æœ‰æ¨æ–‡è³‡æ–™ ---\n",
    "csv_files = sorted(glob.glob(\"data/tariff_data_en/*.csv\"))\n",
    "df_list = [pd.read_csv(f) for f in csv_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. æ¨™æº–åŒ–æ¬„ä½èˆ‡æ™‚é–“è™•ç† ---\n",
    "df.columns = ['Timestamp', 'text', 'sentiment']\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])  # å« UTC æ™‚å€\n",
    "event_date = pd.to_datetime(\"2025-04-04\").tz_localize(\"UTC\")\n",
    "df['period'] = df['Timestamp'].apply(lambda x: 'before' if x < event_date else 'after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:13<00:00, 21.17it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- 3. ä½¿ç”¨é è¨“ç·´ Sentence-BERT å°‡æ¨æ–‡è½‰æˆèªæ„å‘é‡ ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # è¼•é‡å¿«é€Ÿ\n",
    "X = model.encode(df['text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. KMeans èšé¡ ---\n",
    "k = 6\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. PCA é™ç¶­ + ç•«ç¾¤é«”åˆ†å¸ƒåœ– ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "os.makedirs(\"saved_imgs_0404\", exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='tab10', alpha=0.6)\n",
    "plt.title(\"KMeans with SBERT Embedding (PCA)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.savefig(\"saved_imgs_0404/kmeans_pca_sbert.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. ç”¢å‡ºæ¯å€‹ç¾¤çš„ WordCloudï¼ˆç…§èˆŠï¼‰---\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "custom_stopwords = set(['tariff', 'trump','stock'])\n",
    "all_stopwords = list(ENGLISH_STOP_WORDS.union(custom_stopwords))\n",
    "\n",
    "def plot_cluster_wordcloud(df, cluster_num):\n",
    "    text = \" \".join(df[df['cluster'] == cluster_num]['text'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=all_stopwords).generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Cluster {cluster_num} WordCloud\")\n",
    "    plt.savefig(f\"saved_imgs_0404/cluster_{cluster_num}_wordcloud_sbert.png\")\n",
    "    plt.close()\n",
    "\n",
    "for cl in sorted(df['cluster'].unique()):\n",
    "    plot_cluster_wordcloud(df, cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š å„ç¾¤æƒ…ç·’æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\n",
      "sentiment  negative   neutral  positive\n",
      "cluster                                \n",
      "0          0.501894  0.174242  0.323864\n",
      "1          0.536533  0.127507  0.335960\n",
      "2          0.549412  0.164706  0.285882\n",
      "3          0.380933  0.251810  0.367257\n",
      "4          0.504292  0.194421  0.301288\n",
      "5          0.425767  0.164417  0.409816\n",
      "\n",
      "ğŸ“† å„ç¾¤åœ¨äº‹ä»¶å‰/å¾Œçš„æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\n",
      "period      after    before\n",
      "cluster                    \n",
      "0        0.087121  0.912879\n",
      "1        0.376074  0.623926\n",
      "2        0.749412  0.250588\n",
      "3        0.417136  0.582864\n",
      "4        0.419742  0.580258\n",
      "5        0.446626  0.553374\n"
     ]
    }
   ],
   "source": [
    "# --- 7. é¡å¤–åˆ†æè¼¸å‡ºï¼šäº‹ä»¶å‰å¾Œå„ç¾¤æ•¸é‡èˆ‡æƒ…ç·’åˆ†å¸ƒ ---\n",
    "print(\"\\nğŸ“Š å„ç¾¤æƒ…ç·’æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\")\n",
    "print(df.groupby('cluster')['sentiment'].value_counts(normalize=True).unstack().fillna(0))\n",
    "\n",
    "print(\"\\nğŸ“† å„ç¾¤åœ¨äº‹ä»¶å‰/å¾Œçš„æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\")\n",
    "print(pd.crosstab(df['cluster'], df['period'], normalize='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒŸ äº®é»è§€å¯Ÿç¸½çµï¼ˆäº‹ä»¶ç‚º 4/4 è‚¡å¸‚æš´è·Œï¼‰\n",
    "\n",
    "- **Cluster 2ï¼šäº‹ä»¶å¾Œæ¿€å¢ï¼Œåæ˜ ä¸­ç¾è²¿æ˜“èˆ‡è‚¡å¸‚é€£å‹•ææ…Œ**  \n",
    "  è©²ç¾¤ä»¥ `China`, `war`, `tariffs`, `deal`, `talk` ç‚ºæ ¸å¿ƒè©å½™ï¼Œèšç„¦ä¸­ç¾è¡çªèˆ‡æ”¿ç­–äº¤é‹’ã€‚  \n",
    "  æœ‰ **74.9% æ¨æ–‡å‡ºç¾åœ¨äº‹ä»¶å¾Œ**ï¼Œä¸” **è² é¢æƒ…ç·’é«˜é” 54.9%**ï¼Œæ˜¯å° 4/4 å¸‚å ´è¡æ“Šåæ‡‰æœ€ç›´æ¥çš„ä¸€ç¾¤ã€‚\n",
    "\n",
    "- **Cluster 0ï¼šä»¥åŠ æ‹¿å¤§è¦–è§’è¨è«–è²¿æ˜“æ”¿ç­–ï¼Œæ­·å²æˆåˆ†è¼ƒé«˜**  \n",
    "  é—œéµè©å¦‚ `Canada`, `Trudeau`, `threat`, `tariffs`, `American` æŒ‡å‡ºå…¶ç„¦é»åœ¨åŠ ç¾è²¿æ˜“çˆ­ç«¯ï¼Œ  \n",
    "  **91.3% ç™¼è¡¨æ–¼äº‹ä»¶å‰**ï¼Œé¡¯ç¤ºæ­¤ç‚ºæ—©æœŸè­°é¡Œï¼Œèˆ‡ 4/4 è‚¡ç½ç›¸é—œæ€§ä¸é«˜ã€‚\n",
    "\n",
    "- **Cluster 1ï¼šæŠ•è³‡äººè§€é»é¡¯è‘—ï¼Œå±•ç¾å¸‚å ´æ†‚æ…®èˆ‡æ³¢å‹•é æœŸ**  \n",
    "  ä»¥ `market`, `stock`, `investor`, `recession`, `Bitcoin` ç­‰è©ç‚ºä¸»ï¼Œèªæ°£åç„¦æ…®ã€‚  \n",
    "  **37.6% æ¨æ–‡ä¾†è‡ªäº‹ä»¶å¾Œ**ï¼Œä¸” **è² é¢æƒ…ç·’ç‚º 53.7%**ï¼Œåæ˜ é‡‘èå¸‚å ´å°åˆ©ç©ºæ¶ˆæ¯é«˜åº¦æ•æ„Ÿã€‚\n",
    "\n",
    "- **Cluster 3ï¼šåƒ¹æ ¼èˆ‡æ¶ˆè²»å±¤é¢è¨è«–ï¼Œå…·ç¶“æ¿Ÿç†æ€§åˆ†æç‰¹å¾µ**  \n",
    "  è©å½™å¦‚ `price`, `cost`, `consumer`, `import`, `pay`ï¼Œèªæ°£è¼ƒä¸­æ€§ã€åˆ†æå°å‘ã€‚  \n",
    "  é›– **41.7% ç‚ºäº‹ä»¶å¾Œè²¼æ–‡**ï¼Œä½†å…¶è² é¢æƒ…ç·’æ¯”ä¾‹åƒ…ç‚º 38.1%ï¼Œå±¬æ–¼æƒ…ç·’è¼ƒå¹³è¡¡çš„ç¾¤é«”ã€‚\n",
    "\n",
    "- **Cluster 4ï¼šé›†ä¸­æ”¿åºœè¨€è«–èˆ‡å®è§€æ”¿ç­–è©•è«–ï¼Œèªæ°£åæ”¿æ²»æ€§**  \n",
    "  é«˜é »è©å¦‚ `President`, `plan`, `policy`, `economy`, `Donald`ï¼Œåæ˜ æ”¿æ²»é ˜å°èˆ‡ç¶“æ¿Ÿæˆ°ç•¥è¨è«–ã€‚  \n",
    "  ç´„ **42% æ¨æ–‡ç‚ºäº‹ä»¶å¾Œ**ï¼Œè² é¢æƒ…ç·’ä¹Ÿé” **50.4%**ï¼Œä»£è¡¨æ”¿ç¶“è­°é¡Œåœ¨è‚¡ç½å¾Œä»å…·è¨è«–ç†±åº¦ã€‚\n",
    "\n",
    "- **Cluster 5ï¼šç¤¾ç¾¤èªè¨€æ´»èºï¼Œå£èªåŒ–èˆ‡æƒ…ç·’æ³¢å‹•æ˜é¡¯**  \n",
    "  ä½¿ç”¨ `just`, `war`, `day`, `like`, `President`, `threat` ç­‰è©å½™ï¼Œå¸¶æœ‰å³æ™‚è©•è«–èˆ‡ç¶²æ°‘èªæ„Ÿã€‚  \n",
    "  ç‚ºæ­£é¢æƒ…ç·’æœ€é«˜ç¾¤ï¼ˆ**40.9%**ï¼‰ï¼Œ**44.7% ç‚ºäº‹ä»¶å¾Œè²¼æ–‡**ï¼Œå¯èƒ½åŒ…å«å¹½é»˜ã€æˆ²è¬”æˆ–æ”¯æŒç™¼è¨€ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stock market related"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xw/sscnc6jx4kb4klgrdr8sgyz80000gn/T/ipykernel_4748/1006423659.py:25: UserWarning: Glyph 128269 (\\N{LEFT-POINTING MAGNIFYING GLASS}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/var/folders/xw/sscnc6jx4kb4klgrdr8sgyz80000gn/T/ipykernel_4748/1006423659.py:26: UserWarning: Glyph 128269 (\\N{LEFT-POINTING MAGNIFYING GLASS}) missing from font(s) DejaVu Sans.\n",
      "  plt.savefig(\"saved_imgs_0404/event_day_top_words.png\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Step 1ï¼šç¯©é¸äº‹ä»¶ç•¶å¤©çš„æ¨æ–‡\n",
    "event_date = pd.to_datetime(\"2025-04-04\").tz_localize(\"UTC\")\n",
    "same_day_df = df[df['Timestamp'].dt.date == event_date.date()]\n",
    "\n",
    "# Step 2ï¼šä½¿ç”¨ CountVectorizer æŠ½å–å–®å­—é »ç‡\n",
    "vectorizer = CountVectorizer(stop_words='english', max_features=1000)\n",
    "X_count = vectorizer.fit_transform(same_day_df['text'])\n",
    "\n",
    "# Step 3ï¼šçµ±è¨ˆæœ€å¸¸å‡ºç¾çš„è©\n",
    "word_counts = X_count.sum(axis=0).A1\n",
    "vocab = vectorizer.get_feature_names_out()\n",
    "top_words = pd.DataFrame({'word': vocab, 'count': word_counts})\n",
    "top_words = top_words.sort_values(by='count', ascending=False).head(30)\n",
    "\n",
    "# Step 4ï¼šå¯è¦–åŒ–ï¼ˆé¸æ“‡æ€§ï¼‰\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(top_words['word'][::-1], top_words['count'][::-1])\n",
    "plt.title(\"ğŸ” Top Keywords on 2025-04-04 (Stock Plunge Day)\")\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"saved_imgs_0404/event_day_top_words.png\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0409 (é¡å¤–é—œç¨…ç¬¬ä¸€æ³¢æ–½åŠ )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Tweet Content</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-01T22:17:49.000Z</td>\n",
       "      <td>Proposed tariffs on China, Canada, and Mexico ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-03-01T22:27:25.000Z</td>\n",
       "      <td>President Trump says his 25-percent tariff on ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-03-01T23:00:01.000Z</td>\n",
       "      <td>\"You should pay less for someone that has tari...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-03-01T23:00:01.000Z</td>\n",
       "      <td>\"You should pay less for someone that has tari...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-03-01T22:30:20.000Z</td>\n",
       "      <td>Beer Companies Say Trumpâ€™s Aluminum Tariff Wil...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Timestamp  \\\n",
       "0  2025-03-01T22:17:49.000Z   \n",
       "1  2025-03-01T22:27:25.000Z   \n",
       "2  2025-03-01T23:00:01.000Z   \n",
       "3  2025-03-01T23:00:01.000Z   \n",
       "4  2025-03-01T22:30:20.000Z   \n",
       "\n",
       "                                       Tweet Content sentiment  \n",
       "0  Proposed tariffs on China, Canada, and Mexico ...  positive  \n",
       "1  President Trump says his 25-percent tariff on ...  positive  \n",
       "2  \"You should pay less for someone that has tari...  negative  \n",
       "3  \"You should pay less for someone that has tari...  negative  \n",
       "4  Beer Companies Say Trumpâ€™s Aluminum Tariff Wil...  negative  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 1. åˆä½µæ‰€æœ‰æ¨æ–‡è³‡æ–™ ---\n",
    "csv_files = sorted(glob.glob(\"data/tariff_data_en/*.csv\"))\n",
    "df_list = [pd.read_csv(f) for f in csv_files]\n",
    "df = pd.concat(df_list, ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. æ¨™æº–åŒ–æ¬„ä½èˆ‡æ™‚é–“è™•ç† ---\n",
    "df.columns = ['Timestamp', 'text', 'sentiment']\n",
    "df.dropna(subset=['text'], inplace=True)\n",
    "df['Timestamp'] = pd.to_datetime(df['Timestamp'])  # å« UTC æ™‚å€\n",
    "event_date = pd.to_datetime(\"2025-04-09\").tz_localize(\"UTC\")\n",
    "df['period'] = df['Timestamp'].apply(lambda x: 'before' if x < event_date else 'after')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 280/280 [00:17<00:00, 15.97it/s]\n"
     ]
    }
   ],
   "source": [
    "# --- 3. ä½¿ç”¨é è¨“ç·´ Sentence-BERT å°‡æ¨æ–‡è½‰æˆèªæ„å‘é‡ ---\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # è¼•é‡å¿«é€Ÿ\n",
    "X = model.encode(df['text'].tolist(), show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "# --- 4. KMeans èšé¡ ---\n",
    "k = 6\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. PCA é™ç¶­ + ç•«ç¾¤é«”åˆ†å¸ƒåœ– ---\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "\n",
    "os.makedirs(\"saved_imgs_0409\", exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(X_pca[:, 0], X_pca[:, 1], c=df['cluster'], cmap='tab10', alpha=0.6)\n",
    "plt.title(\"KMeans with SBERT Embedding (PCA)\")\n",
    "plt.xlabel(\"PCA 1\")\n",
    "plt.ylabel(\"PCA 2\")\n",
    "plt.colorbar(scatter, label='Cluster')\n",
    "plt.savefig(\"saved_imgs_0409/kmeans_pca_sbert.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. ç”¢å‡ºæ¯å€‹ç¾¤çš„ WordCloudï¼ˆç…§èˆŠï¼‰---\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "custom_stopwords = set(['tariff', 'trump'])\n",
    "all_stopwords = list(ENGLISH_STOP_WORDS.union(custom_stopwords))\n",
    "\n",
    "def plot_cluster_wordcloud(df, cluster_num):\n",
    "    text = \" \".join(df[df['cluster'] == cluster_num]['text'])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white', stopwords=all_stopwords).generate(text)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Cluster {cluster_num} WordCloud\")\n",
    "    plt.savefig(f\"saved_imgs_0409/cluster_{cluster_num}_wordcloud_sbert.png\")\n",
    "    plt.close()\n",
    "\n",
    "for cl in sorted(df['cluster'].unique()):\n",
    "    plot_cluster_wordcloud(df, cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š å„ç¾¤æƒ…ç·’æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\n",
      "sentiment  negative   neutral  positive\n",
      "cluster                                \n",
      "0          0.501894  0.174242  0.323864\n",
      "1          0.536533  0.127507  0.335960\n",
      "2          0.549412  0.164706  0.285882\n",
      "3          0.380933  0.251810  0.367257\n",
      "4          0.504292  0.194421  0.301288\n",
      "5          0.425767  0.164417  0.409816\n",
      "\n",
      "ğŸ“† å„ç¾¤åœ¨äº‹ä»¶å‰/å¾Œçš„æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\n",
      "period      after    before\n",
      "cluster                    \n",
      "0        0.072917  0.927083\n",
      "1        0.315903  0.684097\n",
      "2        0.652941  0.347059\n",
      "3        0.327836  0.672164\n",
      "4        0.333047  0.666953\n",
      "5        0.391411  0.608589\n"
     ]
    }
   ],
   "source": [
    "# --- 7. é¡å¤–åˆ†æè¼¸å‡ºï¼šäº‹ä»¶å‰å¾Œå„ç¾¤æ•¸é‡èˆ‡æƒ…ç·’åˆ†å¸ƒ ---\n",
    "print(\"\\nğŸ“Š å„ç¾¤æƒ…ç·’æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\")\n",
    "print(df.groupby('cluster')['sentiment'].value_counts(normalize=True).unstack().fillna(0))\n",
    "\n",
    "print(\"\\nğŸ“† å„ç¾¤åœ¨äº‹ä»¶å‰/å¾Œçš„æ¯”ä¾‹ï¼ˆrow-normalizedï¼‰:\")\n",
    "print(pd.crosstab(df['cluster'], df['period'], normalize='index'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ“‹ ç¾¤é«”èªæ„ç¸½è¦½è¡¨æ ¼ï¼ˆæ•´åˆèªæ„ã€æƒ…ç·’èˆ‡æ™‚é–“ï¼‰\n",
    "\n",
    "| Cluster | ä¸»é¡Œç„¦é»                         | é«˜é »é—œéµè©ï¼ˆéƒ¨åˆ†ï¼‰                           | èªæ°£å‚¾å‘       | è² é¢æƒ…ç·’æ¯”ä¾‹ | äº‹ä»¶å¾Œä½”æ¯” | å‚™è¨»                             |\n",
    "|---------|----------------------------------|----------------------------------------------|----------------|----------------|------------|----------------------------------|\n",
    "| 0       | ç¾åŠ è²¿æ˜“çˆ­ç«¯èˆ‡åŠ æ‹¿å¤§è§€é»         | Canada, Trudeau, threat, tariffs, product    | æ‰¹åˆ¤ã€é˜²ç¦¦å‹   | 50.2%         | 7.3%       | å¹¾ä¹çš†åœ¨äº‹ä»¶å‰å‡ºç¾ï¼Œç‚ºæ­·å²è­°é¡Œ   |\n",
    "| 1       | å¸‚å ´æ³¢å‹•èˆ‡æŠ•è³‡åæ‡‰               | stock, market, investor, inflation, Bitcoin  | ç„¦æ…®ã€ç†æ€§å‹   | 53.7%         | 31.6%      | é—œæ³¨è‚¡å¸‚èˆ‡é‡‘èè¡æ“Š               |\n",
    "| 2       | ä¸­ç¾è²¿æ˜“æˆ°èˆ‡åœ‹éš›è«‡åˆ¤             | China, deal, war, export, talk               | å°ç«‹ã€æ‰¹åˆ¤å‹   | 54.9%         | 65.3%      | èˆ‡äº‹ä»¶é«˜åº¦ç›¸é—œï¼Œäº‹ä»¶å¾Œæ¿€å¢       |\n",
    "| 3       | é—œç¨…å½±éŸ¿èˆ‡æ¶ˆè²»ç¶“æ¿Ÿ               | tariffs, price, cost, consumer, product      | ä¸­æ€§ã€ç†æ€§å‹   | 38.1%         | 32.8%      | æ¶‰åŠæ°‘ç”Ÿç‰©åƒ¹èˆ‡é€²å‡ºå£ç¨…æ”¶         |\n",
    "| 4       | æ”¿ç­–è©•è«–èˆ‡å®˜æ–¹è¨€è«–åæ‡‰           | President, economy, policy, plan             | è©•è«–æ€§æ··åˆå‹   | 50.4%         | 33.3%      | æ¶‰åŠæ”¿åºœç™¼è¨€èˆ‡æ”¿ç­–æ–¹å‘           |\n",
    "| 5       | ç¶²æ°‘è¼¿è«–èˆ‡ç¤¾ç¾¤å£èªåæ‡‰           | just, like, say, new, talk, war              | å¤šå…ƒã€æƒ…ç·’åŒ–   | 42.6%         | 39.1%      | ç¤¾ç¾¤æ„è¦‹è‡ªç”±ç™¼è¡¨ï¼Œæƒ…ç·’æ³¢å‹•å¤§     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸŒŸ äº®é»è§€å¯Ÿç¸½çµ\n",
    "\n",
    "- **Cluster 2 æ˜¯äº‹ä»¶å¾Œåæ‡‰æœ€å¼·çƒˆçš„ç¾¤é«”**  \n",
    "  æ­¤ç¾¤ä»¥ã€Œä¸­ç¾è²¿æ˜“æˆ°ã€ç‚ºæ ¸å¿ƒä¸»é¡Œï¼ŒåŒ…å«å¤§é‡å¦‚ `China`, `war`, `deal`, `export` ç­‰å°ç«‹æ€§è©å½™ã€‚  \n",
    "  æ¨æ–‡ä¸­æœ‰ **è¶…é 65% å‡ºç¾åœ¨äº‹ä»¶å¾Œ**ï¼Œä¸” **è² é¢æƒ…ç·’ä½”æ¯”é«˜é” 54.9%**ï¼Œé¡¯ç¤ºäº‹ä»¶å¯èƒ½å¼•ç™¼äº†å¤§é‡ä¸å®‰èˆ‡æ‰¹åˆ¤è¨€è«–ã€‚\n",
    "\n",
    "- **Cluster 0 å¹¾ä¹å…¨éƒ¨ç‚ºäº‹ä»¶å‰çš„æ­·å²è­°é¡Œ**  \n",
    "  èšç„¦ã€Œç¾åŠ è²¿æ˜“çˆ­ç«¯ã€èˆ‡åŠ æ‹¿å¤§è§’åº¦ï¼ˆè©å½™å¦‚ `Canada`, `Trudeau`, `threat`ï¼‰ï¼Œ  \n",
    "  **äº‹ä»¶å¾Œåƒ…ä½” 7.3%**ï¼Œèªªæ˜æ­¤ä¸»é¡Œå¯èƒ½å·²é€æ¼¸é™æº«ï¼Œä¸”è¨è«–é›†ä¸­æ–¼éå¾€æ”¿ç­–èˆ‡å½±éŸ¿ã€‚\n",
    "\n",
    "- **Cluster 5 ç‚ºæƒ…ç·’æœ€æ­£å‘çš„ç¾¤é«”ï¼Œèªè¨€é¢¨æ ¼åç¤¾ç¾¤èˆ‡å£èªåŒ–**  \n",
    "  å¸¸è¦‹è©å½™å¦‚ `just`, `like`, `say`, `want`ï¼Œé¡¯ç¤ºç”¨èªè‡ªç„¶ã€è¼•é¬†ï¼Œç¬¦åˆç¤¾äº¤å¹³å°ç‰¹å¾µã€‚  \n",
    "  **æ­£å‘æƒ…ç·’ä½”æ¯”é” 40.9%**ï¼Œç‚ºå…­ç¾¤ä¹‹æœ€ï¼Œå‘ˆç¾è¼¿è«–è‡ªç”±è¡¨é”èˆ‡éƒ¨åˆ†å¹½é»˜æˆ–æ”¯æŒæ€§èªæ°£ã€‚\n",
    "\n",
    "- **Cluster 3 è¨è«–ç„¦é»åå‘ç¶“æ¿Ÿè² æ“”èˆ‡æ¶ˆè²»è€…è§’åº¦**  \n",
    "  é—œæ³¨å¦‚ `cost`, `price`, `consumer`, `impact` ç­‰è©å½™ï¼Œèªæ°£æ•´é«”åä¸­æ€§èˆ‡ç†æ€§ã€‚  \n",
    "  é›–ä¸å±¬æ–¼æƒ…ç·’æ¥µç«¯ç¾¤é«”ï¼Œä½†ä¹Ÿå…·å‚™é•·æœŸè¨è«–åƒ¹å€¼ï¼Œåæ˜ æ”¿ç­–å°ç”Ÿæ´»å±¤é¢çš„å¯¦éš›å½±éŸ¿ã€‚\n",
    "\n",
    "- **Cluster 1 è¡¨ç¾å‡ºå°å¸‚å ´çš„ç„¦æ…®èˆ‡è§€æœ›æƒ…ç·’**  \n",
    "  ä¸»é¡Œé›†ä¸­æ–¼ `stock`, `market`, `investor`, `recession` ç­‰è©ï¼Œ  \n",
    "  ä¸¦æœ‰ **53.7% çš„è² é¢æƒ…ç·’**ï¼Œé¡¯ç¤ºç¶“æ¿Ÿä¸ç¢ºå®šæ€§å¼•ç™¼çš„æŠ•è³‡æ†‚æ…®æ™®éå­˜åœ¨ã€‚\n",
    "\n",
    "- **Cluster 4 æ¶‰åŠæ”¿åºœèˆ‡é ˜å°äººè¨€è«–ï¼Œæƒ…ç·’å…©æ¥µåŒ–**  \n",
    "  é«˜é »è©åŒ…å« `President`, `policy`, `plan`, `economy`ï¼Œæ¶‰åŠå®˜æ–¹ç™¼è¨€èˆ‡æ”¿è¦‹ã€‚  \n",
    "  é›–åˆ†å¸ƒç©©å®šï¼Œä½†æƒ…ç·’å®¹æ˜“éš¨ç«‹å ´è®ŠåŒ–è€Œåˆ†åŒ–ï¼Œå‘ˆç¾è©•è«–æ€§èˆ‡å°ç«‹æ€§æ··åˆèªæ°£ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
