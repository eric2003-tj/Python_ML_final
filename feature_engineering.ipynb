{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 萃取完成，以下是特徵預覽：\n",
      "         date  num_tweets  avg_length  avg_num_words  avg_hashtags  \\\n",
      "0  2025-03-01          57  186.807018      27.807018      0.526316   \n",
      "1  2025-03-02         150  183.986667      27.406667      0.386667   \n",
      "2  2025-03-03         205  163.819512      25.600000      0.165854   \n",
      "3  2025-03-04         215  178.246512      27.265116      0.344186   \n",
      "4  2025-03-05         216  172.273148      26.629630      0.435185   \n",
      "\n",
      "   avg_mentions  avg_uppercase_ratio  prop_negative  prop_neutral  \\\n",
      "0      0.157895             0.061645       0.614035      0.157895   \n",
      "1      0.153333             0.072549       0.546667      0.173333   \n",
      "2      0.112195             0.067358       0.478049      0.234146   \n",
      "3      0.162791             0.066337       0.460465      0.167442   \n",
      "4      0.236111             0.061758       0.393519      0.324074   \n",
      "\n",
      "   prop_positive  vader_avg_compound  vader_std_compound  vader_max_compound  \\\n",
      "0       0.228070           -0.200100            0.484145              0.9309   \n",
      "1       0.280000           -0.190273            0.445028              0.8122   \n",
      "2       0.287805           -0.117938            0.429847              0.8625   \n",
      "3       0.372093           -0.031871            0.534663              0.9081   \n",
      "4       0.282407           -0.107240            0.473492              0.8834   \n",
      "\n",
      "   vader_min_compound  avg_sentiment_score  day_of_week  is_weekend  \n",
      "0             -0.8519             0.614035            5           1  \n",
      "1             -0.9300             0.733333            6           1  \n",
      "2             -0.9201             0.809756            0           0  \n",
      "3             -0.9622             0.911628            1           0  \n",
      "4             -0.9590             0.888889            2           0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# === 設定資料夾 ===\n",
    "data_folder = \"data/tariff_data_en\"  # <-- 改成你的資料夾名稱\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiment_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "# === 定義特徵萃取函數 ===\n",
    "def extract_day_features(df, date_str):\n",
    "    df = df.copy()\n",
    "    df[\"sentiment_score\"] = df[\"sentiment\"].map(sentiment_map)\n",
    "    df[\"length\"] = df[\"Tweet Content\"].astype(str).apply(len)\n",
    "    df[\"num_words\"] = df[\"Tweet Content\"].astype(str).apply(lambda x: len(x.split()))\n",
    "    df[\"num_hashtags\"] = df[\"Tweet Content\"].astype(str).str.count(\"#\")\n",
    "    df[\"num_mentions\"] = df[\"Tweet Content\"].astype(str).str.count(\"@\")\n",
    "    df[\"uppercase_ratio\"] = df[\"Tweet Content\"].astype(str).apply(\n",
    "        lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
    "    df[\"vader_compound\"] = df[\"Tweet Content\"].astype(str).apply(\n",
    "        lambda x: analyzer.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "    total = len(df)\n",
    "    return {\n",
    "        \"date\": date_str,\n",
    "        \"num_tweets\": total,\n",
    "        \"avg_length\": df[\"length\"].mean(),\n",
    "        \"avg_num_words\": df[\"num_words\"].mean(),\n",
    "        \"avg_hashtags\": df[\"num_hashtags\"].mean(),\n",
    "        \"avg_mentions\": df[\"num_mentions\"].mean(),\n",
    "        \"avg_uppercase_ratio\": df[\"uppercase_ratio\"].mean(),\n",
    "        \"prop_negative\": len(df[df[\"sentiment\"] == \"negative\"]) / total if total else 0,\n",
    "        \"prop_neutral\": len(df[df[\"sentiment\"] == \"neutral\"]) / total if total else 0,\n",
    "        \"prop_positive\": len(df[df[\"sentiment\"] == \"positive\"]) / total if total else 0,\n",
    "        \"vader_avg_compound\": df[\"vader_compound\"].mean(),\n",
    "        \"vader_std_compound\": df[\"vader_compound\"].std(),\n",
    "        \"vader_max_compound\": df[\"vader_compound\"].max(),\n",
    "        \"vader_min_compound\": df[\"vader_compound\"].min(),\n",
    "        \"avg_sentiment_score\": df[\"sentiment_score\"].mean(),\n",
    "        \"day_of_week\": datetime.strptime(date_str, \"%Y-%m-%d\").weekday(),\n",
    "        \"is_weekend\": 1 if datetime.strptime(date_str, \"%Y-%m-%d\").weekday() >= 5 else 0\n",
    "    }\n",
    "\n",
    "# === 讀取所有 CSV 並處理 ===\n",
    "feature_rows = []\n",
    "for filename in sorted(os.listdir(data_folder)):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            # 推論日期\n",
    "            date_str = filename.replace(\"tariff_data_\", \"\").replace(\".csv\", \"\")\n",
    "            if \"-\" not in date_str:  # 像 20250403\n",
    "                date_str = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "            features = extract_day_features(df, date_str)\n",
    "            feature_rows.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading {filename}: {e}\")\n",
    "\n",
    "# === 建立結果 DataFrame ===\n",
    "features_df = pd.DataFrame(feature_rows)\n",
    "print(\"✅ 萃取完成，以下是特徵預覽：\")\n",
    "print(features_df.head())\n",
    "\n",
    "# === 可選：儲存為 CSV ===\n",
    "features_df.to_csv(\"daily_sentiment_features.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 萃取完成，以下是特徵預覽：\n",
      "         date  num_tweets  avg_length  avg_num_words  avg_hashtags  \\\n",
      "0  2025-05-01         136  174.205882      27.169118      0.308824   \n",
      "1  2025-05-02          57  173.929825      26.438596      0.368421   \n",
      "2  2025-05-03         140  179.421429      27.014286      0.428571   \n",
      "3  2025-05-04         148  143.945946      24.182432      0.148649   \n",
      "4  2025-05-05         137  160.832117      24.364964      0.357664   \n",
      "\n",
      "   avg_mentions  avg_uppercase_ratio  prop_negative  prop_neutral  \\\n",
      "0      0.250000             0.072426       0.448529      0.205882   \n",
      "1      0.210526             0.066371       0.350877      0.210526   \n",
      "2      0.128571             0.048738       0.471429      0.200000   \n",
      "3      0.087838             0.068771       0.324324      0.317568   \n",
      "4      0.175182             0.058099       0.357664      0.306569   \n",
      "\n",
      "   prop_positive  vader_avg_compound  vader_std_compound  vader_max_compound  \\\n",
      "0       0.345588           -0.056668            0.463832              0.9087   \n",
      "1       0.438596            0.046686            0.515141              0.9038   \n",
      "2       0.328571           -0.063092            0.453382              0.8720   \n",
      "3       0.358108            0.017781            0.432513              0.8943   \n",
      "4       0.335766            0.000934            0.399701              0.8930   \n",
      "\n",
      "   vader_min_compound  avg_sentiment_score  day_of_week  is_weekend  \n",
      "0             -0.8850             0.897059            3           0  \n",
      "1             -0.9395             1.087719            4           0  \n",
      "2             -0.9169             0.857143            5           1  \n",
      "3             -0.9013             1.033784            6           1  \n",
      "4             -0.9136             0.978102            0           0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# === 設定資料夾 ===\n",
    "data_folder = \"data/tariff_data_en_test\"  # <-- 改成你的資料夾名稱\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiment_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "# === 定義特徵萃取函數 ===\n",
    "def extract_day_features(df, date_str):\n",
    "    df = df.copy()\n",
    "    df[\"sentiment_score\"] = df[\"sentiment\"].map(sentiment_map)\n",
    "    df[\"length\"] = df[\"Tweet Content\"].astype(str).apply(len)\n",
    "    df[\"num_words\"] = df[\"Tweet Content\"].astype(str).apply(lambda x: len(x.split()))\n",
    "    df[\"num_hashtags\"] = df[\"Tweet Content\"].astype(str).str.count(\"#\")\n",
    "    df[\"num_mentions\"] = df[\"Tweet Content\"].astype(str).str.count(\"@\")\n",
    "    df[\"uppercase_ratio\"] = df[\"Tweet Content\"].astype(str).apply(\n",
    "        lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
    "    df[\"vader_compound\"] = df[\"Tweet Content\"].astype(str).apply(\n",
    "        lambda x: analyzer.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "    total = len(df)\n",
    "    return {\n",
    "        \"date\": date_str,\n",
    "        \"num_tweets\": total,\n",
    "        \"avg_length\": df[\"length\"].mean(),\n",
    "        \"avg_num_words\": df[\"num_words\"].mean(),\n",
    "        \"avg_hashtags\": df[\"num_hashtags\"].mean(),\n",
    "        \"avg_mentions\": df[\"num_mentions\"].mean(),\n",
    "        \"avg_uppercase_ratio\": df[\"uppercase_ratio\"].mean(),\n",
    "        \"prop_negative\": len(df[df[\"sentiment\"] == \"negative\"]) / total if total else 0,\n",
    "        \"prop_neutral\": len(df[df[\"sentiment\"] == \"neutral\"]) / total if total else 0,\n",
    "        \"prop_positive\": len(df[df[\"sentiment\"] == \"positive\"]) / total if total else 0,\n",
    "        \"vader_avg_compound\": df[\"vader_compound\"].mean(),\n",
    "        \"vader_std_compound\": df[\"vader_compound\"].std(),\n",
    "        \"vader_max_compound\": df[\"vader_compound\"].max(),\n",
    "        \"vader_min_compound\": df[\"vader_compound\"].min(),\n",
    "        \"avg_sentiment_score\": df[\"sentiment_score\"].mean(),\n",
    "        \"day_of_week\": datetime.strptime(date_str, \"%Y-%m-%d\").weekday(),\n",
    "        \"is_weekend\": 1 if datetime.strptime(date_str, \"%Y-%m-%d\").weekday() >= 5 else 0\n",
    "    }\n",
    "\n",
    "# === 讀取所有 CSV 並處理 ===\n",
    "feature_rows = []\n",
    "for filename in sorted(os.listdir(data_folder)):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            # 推論日期\n",
    "            date_str = filename.replace(\"tariff_data_\", \"\").replace(\".csv\", \"\")\n",
    "            if \"-\" not in date_str:  # 像 20250403\n",
    "                date_str = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "            features = extract_day_features(df, date_str)\n",
    "            feature_rows.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading {filename}: {e}\")\n",
    "\n",
    "# === 建立結果 DataFrame ===\n",
    "features_df = pd.DataFrame(feature_rows)\n",
    "print(\"✅ 萃取完成，以下是特徵預覽：\")\n",
    "print(features_df.head())\n",
    "\n",
    "# === 可選：儲存為 CSV ===\n",
    "features_df.to_csv(\"daily_sentiment_features_test.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ 萃取完成，以下是特徵預覽：\n",
      "         date  num_tweets  avg_length  avg_num_words  avg_hashtags  \\\n",
      "0  2018-07-01         129  201.410853      24.403101      0.666667   \n",
      "1  2018-07-02         139  187.489209      23.158273      0.611511   \n",
      "2  2018-07-03         144  189.986111      22.875000      0.958333   \n",
      "3  2018-07-04         140  180.064286      22.514286      0.842857   \n",
      "4  2018-07-05         140  169.135714      20.928571      0.850000   \n",
      "\n",
      "   avg_mentions  avg_uppercase_ratio  prop_negative  prop_neutral  \\\n",
      "0      0.240310             0.052229       0.426357      0.193798   \n",
      "1      0.381295             0.059080       0.474820      0.251799   \n",
      "2      0.409722             0.067989       0.416667      0.312500   \n",
      "3      0.271429             0.069381       0.521429      0.192857   \n",
      "4      0.207143             0.063240       0.528571      0.214286   \n",
      "\n",
      "   prop_positive  vader_avg_compound  vader_std_compound  vader_max_compound  \\\n",
      "0       0.379845           -0.011481            0.497687              0.9654   \n",
      "1       0.273381           -0.074474            0.474154              0.9032   \n",
      "2       0.270833           -0.062131            0.373010              0.8348   \n",
      "3       0.285714           -0.118252            0.469507              0.9042   \n",
      "4       0.257143           -0.153966            0.467795              0.9081   \n",
      "\n",
      "   vader_min_compound  avg_sentiment_score  day_of_week  is_weekend  \n",
      "0             -0.8997             0.953488            6           1  \n",
      "1             -0.9580             0.798561            0           0  \n",
      "2             -0.8176             0.854167            1           0  \n",
      "3             -0.9036             0.764286            2           0  \n",
      "4             -0.9022             0.728571            3           0  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# === 設定資料夾 ===\n",
    "data_folder = \"data/cross_val\"  # <-- 改成你的資料夾名稱\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "sentiment_map = {\"negative\": 0, \"neutral\": 1, \"positive\": 2}\n",
    "\n",
    "# === 定義特徵萃取函數 ===\n",
    "def extract_day_features(df, date_str):\n",
    "    df = df.copy()\n",
    "    df[\"sentiment_score\"] = df[\"sentiment\"].map(sentiment_map)\n",
    "    df[\"length\"] = df[\"Tweet Content\"].astype(str).apply(len)\n",
    "    df[\"num_words\"] = df[\"Tweet Content\"].astype(str).apply(lambda x: len(x.split()))\n",
    "    df[\"num_hashtags\"] = df[\"Tweet Content\"].astype(str).str.count(\"#\")\n",
    "    df[\"num_mentions\"] = df[\"Tweet Content\"].astype(str).str.count(\"@\")\n",
    "    df[\"uppercase_ratio\"] = df[\"Tweet Content\"].astype(str).apply(\n",
    "        lambda x: sum(1 for c in x if c.isupper()) / len(x) if len(x) > 0 else 0)\n",
    "    df[\"vader_compound\"] = df[\"Tweet Content\"].astype(str).apply(\n",
    "        lambda x: analyzer.polarity_scores(x)[\"compound\"])\n",
    "\n",
    "    total = len(df)\n",
    "    return {\n",
    "        \"date\": date_str,\n",
    "        \"num_tweets\": total,\n",
    "        \"avg_length\": df[\"length\"].mean(),\n",
    "        \"avg_num_words\": df[\"num_words\"].mean(),\n",
    "        \"avg_hashtags\": df[\"num_hashtags\"].mean(),\n",
    "        \"avg_mentions\": df[\"num_mentions\"].mean(),\n",
    "        \"avg_uppercase_ratio\": df[\"uppercase_ratio\"].mean(),\n",
    "        \"prop_negative\": len(df[df[\"sentiment\"] == \"negative\"]) / total if total else 0,\n",
    "        \"prop_neutral\": len(df[df[\"sentiment\"] == \"neutral\"]) / total if total else 0,\n",
    "        \"prop_positive\": len(df[df[\"sentiment\"] == \"positive\"]) / total if total else 0,\n",
    "        \"vader_avg_compound\": df[\"vader_compound\"].mean(),\n",
    "        \"vader_std_compound\": df[\"vader_compound\"].std(),\n",
    "        \"vader_max_compound\": df[\"vader_compound\"].max(),\n",
    "        \"vader_min_compound\": df[\"vader_compound\"].min(),\n",
    "        \"avg_sentiment_score\": df[\"sentiment_score\"].mean(),\n",
    "        \"day_of_week\": datetime.strptime(date_str, \"%Y-%m-%d\").weekday(),\n",
    "        \"is_weekend\": 1 if datetime.strptime(date_str, \"%Y-%m-%d\").weekday() >= 5 else 0\n",
    "    }\n",
    "\n",
    "# === 讀取所有 CSV 並處理 ===\n",
    "feature_rows = []\n",
    "for filename in sorted(os.listdir(data_folder)):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        filepath = os.path.join(data_folder, filename)\n",
    "        try:\n",
    "            df = pd.read_csv(filepath)\n",
    "            # 推論日期\n",
    "            date_str = filename.replace(\"tariff_data_\", \"\").replace(\".csv\", \"\")\n",
    "            if \"-\" not in date_str:  # 像 20250403\n",
    "                date_str = f\"{date_str[:4]}-{date_str[4:6]}-{date_str[6:]}\"\n",
    "            features = extract_day_features(df, date_str)\n",
    "            feature_rows.append(features)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error reading {filename}: {e}\")\n",
    "\n",
    "# === 建立結果 DataFrame ===\n",
    "features_df = pd.DataFrame(feature_rows)\n",
    "print(\"✅ 萃取完成，以下是特徵預覽：\")\n",
    "print(features_df.head())\n",
    "\n",
    "# === 可選：儲存為 CSV ===\n",
    "features_df.to_csv(\"cross_val.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qiskit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
